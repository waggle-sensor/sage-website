"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6284],{3770:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-data-2-27373e9e229c2b8f43464a6ef5a74c7f.png"},28453:(e,t,s)=>{s.d(t,{R:()=>r,x:()=>o});var a=s(96540);const i={},n=a.createContext(i);function r(e){const t=a.useContext(n);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(n.Provider,{value:t},e.children)}},33937:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-data-1-7fd73ecdf70427d4ffd6b9e9180f4b1e.png"},64696:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-waggle-153e732d68a25417138d1f040bbf2c0f.png"},68362:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-plugin-traffic-c302ed69ee5f9fe8b4d082448d4eb047.png"},71888:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-framework-8c7942e0b71e8ca69c53d3c1427d3441.jpeg"},74098:(e,t,s)=>{s.d(t,{A:()=>a});const a=s.p+"assets/images/resource-management-nx-8469c6bfe29526302d41ce09e600e270.jpeg"},75687:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"recent/resource-management","title":"Resource Management at the Edge","description":"Abstract","source":"@site/science/recent/resource-management.md","sourceDirName":"recent","slug":"/recent/resource-management","permalink":"/science/recent/resource-management","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Finding Events in Real Time","permalink":"/science/recent/finding-events"},"next":{"title":"Sound Separation","permalink":"/science/recent/sound-separation"}}');var i=s(74848),n=s(28453);const r={sidebar_position:2},o="Resource Management at the Edge",l={},c=[{value:"Abstract",id:"abstract",level:2},{value:"Background and Motivation",id:"background-and-motivation",level:2},{value:"A look at the Framework",id:"a-look-at-the-framework",level:2},{value:"Gathering Data",id:"gathering-data",level:2},{value:"Future Directions",id:"future-directions",level:2},{value:"Acknowledgements",id:"acknowledgements",level:2},{value:"References",id:"references",level:2}];function d(e){const t={a:"a",blockquote:"blockquote",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",ol:"ol",p:"p",...(0,n.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"resource-management-at-the-edge",children:"Resource Management at the Edge"})}),"\n",(0,i.jsx)(t.h2,{id:"abstract",children:"Abstract"}),"\n",(0,i.jsx)(t.p,{children:"Waggle is a state-of-the-art open-source platform for developing and deploying novel artificial intelligence algorithms and new sensors into distributed sensor networks. This platform has allowed for researchers to make scientific advancements in diverse environments. Despite its success and technological sophistication, Waggle has its shortcomings. For example, the current Waggle infrastructure has no notion of resource management. Instead, it attempts to use resources conservatively\u2013directly impacting the performance of individual nodes."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"An image of several wild Waggle nodes",src:s(64696).A+"",width:"2664",height:"1797"})}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Wild Waggle Nodes"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"To better understand resource usage within the Waggle infrastructure, we are proposing a standard set of key metrics for resource utilization, designing a standardized system that mimics the Waggle nodes, developing a data collection pipeline, establishing an edge-specific resource utilization dataset, and building tools to analyze this dataset. In alignment with Waggle\u2019s mission, we hope to open the door for other computer scientists to make contributions to resource management at the edge. Ultimately, our work will allow for more efficient computing at the edge through the Waggle infrastructure."}),"\n",(0,i.jsx)(t.h2,{id:"background-and-motivation",children:"Background and Motivation"}),"\n",(0,i.jsx)(t.p,{children:"Most estimates place the number of edge computing devices in the tens of billions, and this is only expected to grow. With single purpose edge devices, resource utilization is understood at the time of design. However, in general purpose systems such as Waggle, resource utilization is an open problem. A better understanding of resource utilization can allow for smarter job scheduling, smarter interactions with cloud and peer devices, and create more performant systems. While these contributions are small at the scale of a single device, they add up at the scale of the edge."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"An image of an NVIDIA Jetson Xavier NX",src:s(74098).A+"",width:"4032",height:"3024"})}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"An NVIDIA Jetson NX, the compute inside a Waggle node"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"The necessity of resource management can be seen in the use of AI applications via Waggle. Summer student Ryan Rearden ran two recent multi-modal models that captioned a video clip. These models used nearly one hundred percent of the CPU for nearly ten hours each. With the growth of modern models, the necessity of real-time resource management is a must for general purpose AI edge systems like Waggle."}),"\n",(0,i.jsx)(t.h2,{id:"a-look-at-the-framework",children:"A look at the Framework"}),"\n",(0,i.jsx)(t.p,{children:"To properly understand resource utilization, we first need to understand what our goal is. We chose power as our key metric to consider due to the power limitations and controls that exist within the Waggle ecosystem. On top of this, we identified CPU and GPU metrics as key contributors to power metrics. Therefore, when designing our system, we are focused on power, CPU, and GPU metrics. We highlighted power utilization, container level cpu utilization, system level cpu utilization, cpu frequency, system level gpu utilization, and gpu frequency as key metrics."}),"\n",(0,i.jsx)(t.p,{children:"Now that we have identified our key metrics, we want to think about how we will develop a framework to obtain, store, display, and analyze them. First and foremost, we want this framework to be reproducible, flexible, and reliable. So, with that in mind, we want to take advantage of existing tools in building our framework. For provisioning devices, we use a customizable ansible script that provisions both edge devices and a metrics server. Note that these can be the same device if desired. For gathering metrics, we use Google\u2019s CAdvisor, which collects container level metrics, and Waggle\u2019s Jetson Exporter, which parses NVIDIA\u2019s tegrastats tool for system level metrics. For storing metrics, we use Grafana\u2019s Mimir, which is a time series metrics database. And finally, for displaying metrics, we use Grafana."}),"\n",(0,i.jsx)(t.p,{children:"Since these are existing tools, we can implement the framework using the customizable ansible script that was mentioned earlier. Within this ansible script, we set up kubernetes to manage all running objects. Then, on the edge devices, we set up metrics gathering tools such as CAdvisor and Jetson Exporter. On the metrics server we set up metrics storage and display objects like Mimir and Grafana. All of this is managed through a set of kubernetes objects within its own namespace."}),"\n",(0,i.jsx)(t.p,{children:"To break down the ansible script into a flexible manner as we have mentioned, we highlight four key subprocesses that can be enabled on command. This is placed on top of a reusable base of kubernetes and other useful tools. We identify these four key areas as gathering metrics, storing metrics, display metrics, and using an NVIDIA graphics card. This level of control allows for multiple setups when gathering metrics. The most common in our use cases is combining gathering metrics with the use of an NVIDIA graphics card on our edge devices with storing and displaying metrics on our metrics server."}),"\n",(0,i.jsx)(t.p,{children:"The final part of our framework is a simple and flexible data pipeline that allows users to pull data from our metrics server. Since our metrics server is in the prometheus format, it is possible to use any prometheus client as a data pipeline or write your own."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"An image describing the metrics gathering framework",src:s(71888).A+"",width:"1472",height:"1322"})}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"The Framework"}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"gathering-data",children:"Gathering Data"}),"\n",(0,i.jsx)(t.p,{children:"Once we have developed our framework, we want to think about gathering data. Remember that one of our goals is to develop an edge computing dataset. With that in mind, we want to gather data from existing SAGE applications. These can fairly easily be run on the Waggle infrastructure and on our testbed that mimics it. That being said, there are a limited number of SAGE applications and they mostly focus on sensor data processing. To get a more holistic dataset, we can also simulate a program to collect the data that we need."}),"\n",(0,i.jsx)(t.p,{children:"In order to simulate a program, we first need to think about what a program is in theory. We can think about a program as a black box. Within the problem space of metrics gathering, we can think about this program as a time-series set of resources usages Ri where each set corresponds to a time ti. Now, to represent any program, we let this set of resources R vary within the space of available resources. Finally, to simulate all possible programs, we can vary the length of ti and the set Ri randomly. As we do this to a greater degree, we are closer to simulating all possible programs. However, since this is not possible, it suffices to randomize our data to choose uniformly from this set."}),"\n",(0,i.jsx)(t.p,{children:"To simulate a program, we use existing stress tools to vary the load on the system. The first tool is stressng, a tool for stressing cpu. The second tool is gpu-stress-test, a Waggle tool for stressing gpu. By combining them together with a controller that manages resources, we create a new program that enacts variable stress on the system. We chose these two programs because we identified CPU and GPU as key metrics for power utilization. In the future, adding more avenues of stress is as simple as incorporating them into the resource controller."}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.img,{alt:"An image showing the relationship between system level cpu usage and power",src:s(33937).A+"",width:"580",height:"432"}),"\n",(0,i.jsx)(t.img,{alt:"An image showing the relationship between container level cpu usage and power",src:s(3770).A+"",width:"580",height:"432"})]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Two plots gathered from simulating a program"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Now the other part of our dataset is built of SAGE applications themselves. Since we have designed our system with a black box program in mind, it is fairly straightforward to gather data from SAGE applications. All that is required are a few pieces of Waggle infrastructure and we can run SAGE applications on our test bed. Once we have these, we are able to run SAGE applications and profile their resource utilization based on the key metrics we identified earlier."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"An image showing time series resource data gathered from the framework",src:s(68362).A+"",width:"2000",height:"1000"})}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsx)(t.p,{children:"Data gathered from monitoring a SAGE application"}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Finally, the last way that we want to add variation in our dataset is through gathering data on multiple devices. The Waggle stack contains several different computation devices\u2013including Raspberry Pis, NVIDIA Jetson NXs, and NVIDIA Jetson Nanos. To account for all of these while we gather data, it is important to apply our data gathering techniques across a variety of devices. Furthermore, the Waggle infrastructure is designed to be distributed. By gathering data from multiple devices, we can simulate a distributed network. Ultimately, making our testbed and data gathering sources simulate the Waggle ecosystem will give us the best dataset possible."}),"\n",(0,i.jsx)(t.h2,{id:"future-directions",children:"Future Directions"}),"\n",(0,i.jsx)(t.p,{children:"Despite our progress, we are far from answering the question: \u201cHow do we save energy at the edge?\u201d In short, our work is the foundation for future work. I\u2019d like to highlight two main avenues that this work should take."}),"\n",(0,i.jsx)(t.p,{children:"First, it is important to answer that question that was posed above. We have started work with a group of optimization researchers at Northwestern University to work on control of the Waggle system. Through smarter scheduling, real time control of edge computing devices, and analysis of SAGE applications, we should be able to save energy at the edge. Providing an edge computing dataset is the first step to implementing all of these solutions."}),"\n",(0,i.jsx)(t.p,{children:"Second, it is important for the Waggle infrastructure to develop a testing environment. During the course of my internship a SAGE migration halted almost all work for over a week. At this time, the entire SAGE/Waggle team was struggling to make progress on their work. Without physical access to the Waggle nodes, there was no environment for people to test their work. As with most infrastructures, it is important to have a testing environment for people to start their work in. Our work this summer has started the process of developing a Waggle test environment. With further development on our testbed, we would be able to simulate a Waggle node for testing purposes."}),"\n",(0,i.jsx)(t.h2,{id:"acknowledgements",children:"Acknowledgements"}),"\n",(0,i.jsx)(t.p,{children:"I would like to give thanks to Yongho Kim for his work as my mentor. He has been incredibly supportive and encouraging as I have completed my internship. I would also like to thank Andrew Siegel for pointing me in the direction of the SULI internship. Finally, I would like to thank all of the Waggle/SAGE team for all of their ideas and support throughout the summer."}),"\n",(0,i.jsx)(t.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Argonne National Laboratory, Sage Continuum, ",(0,i.jsx)(t.a,{href:"https://sagecontinuum.org/",children:"https://sagecontinuum.org/"})]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Argonne National Laboratory, Waggle AI, ",(0,i.jsx)(t.a,{href:"https://wa8.gl/",children:"https://wa8.gl/"})]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);